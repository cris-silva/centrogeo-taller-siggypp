---
title: "4. Web scraping y automatización III"
format: html
editor: visual
---

## Introducción

Se hará en estas etapas:

Observar cómo funciona la página de consulta

Identificar la estructura de la página de consulta ylos elementos que se van a extraer

Crear procedimientos para extraer los datos de cada sección de la página de consulta

Automatizar para repetir el procedimiento de extracción de datos de cada ficha

Acumular los registros extraídos en una misma tabla y limpiarla.

Geocodificar las direcciones y guardar como capa geográfica.

## Objetivo

## Preparación del entorno

```{r Cargar los paquetes}
library(tidyverse)
library(janitor)
library(rvest)
library(RSelenium)
library(tidygeocoder)
library(sf)
library(tmap)
```

### Iniciar servidor de Selenium

```{r Iniciar Selenium}
servidor_selenium <- rsDriver(browser = "firefox")
```

```{r Crear el controlador del explorador web}
controlador <- servidor_selenium$client
```

### Identificación de los controles de la página

```{r Abrir la página de descarga}
pagina_ficha <- "https://catalogonacionalmhi.inah.gob.mx/consulta_publica/detalle/"
id_ficha <- 9000 # ID de prueba

controlador$navigate(str_c(pagina_ficha, id_ficha))
```

Expandir todos los contenedores de la ficha:

```{r Expandir contenedores}
# Crear una instancia del botón Expandir todos:
boton_expandir_todos <- controlador$findElement(using = "xpath",
                                                value = '//*[@id="btnExpandir"]')

# Presionar el botón para expandir los contenedores
boton_expandir_todos$clickElement()
```

Descargar el código fuente de la página:

```{r Guardar el código fuente de la ficha}
# Guarda el contenido de la página en una variable
codigo_fuente <- controlador$getPageSource()

# Extraer con rvest el código fuente de la lista obtenida con Selenium:
html_ficha <- 
  read_html(codigo_fuente[[1]])
```

### Extracción de los campos:

```{r Extraer datos del encabezado}
# Buscar los elementos donde están los datos, extraer y limpiar el texto
datos_contenedor_encabezado <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="encabezado"]') %>% 
  html_children() %>% 
  html_children() %>% 
  html_children() %>% 
  html_children() %>% # Expandir hasta los elementos de cuarto nivel (filas)
  html_text() %>% 
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Agregar nombres de variables faltantes
datos_contenedor_encabezado[1] <- 
  str_c("Tipo: ", datos_contenedor_encabezado[1])

datos_contenedor_encabezado[5] <- 
  str_c("Validación: ", datos_contenedor_encabezado[5])

# Cosnervar las 5 primeras filas
datos_contenedor_encabezado <-
  datos_contenedor_encabezado[1:5]

# Ver el resultado
datos_contenedor_encabezado
```

```{r Extraer tipo de ficha}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_1 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion1"]') %>% # Buscar el elemento del título
  html_children() %>% 
  html_children() %>% 
  html_children() %>% # Expandir hasta los elementos de tercer nivel (filas)
  html_text() %>% # Extraer el texto de los elementos
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Agregar un prefijo con la sección
datos_contenedor_1 <- str_c("S1_", datos_contenedor_1)

# Ver el resultado
datos_contenedor_1
```

Extraer la URL del mapa de Google con las coordenadas:

```{r Extraer URL del mapa}
# Buscar la URL origen del mapa de Google
datos_contenedor_mapa <-
  html_ficha %>%
  html_element(xpath = '//*[@id="divSeccion2"]') %>% # Buscar la sección donde está el mapa
  html_element("a") %>% # Buscar el primer link con la URL del mapa
  html_attr("href") %>%  # Extraer la URL del mapa
  replace_na("") # Si no hay mapa, reemplazar el valor vacío NA con un espacio

# Agregar el nombre del campo al valor:
datos_contenedor_mapa <-
  str_c("S2_Google Maps: ",
        datos_contenedor_mapa)

# Ver el resultado
datos_contenedor_mapa
```

```{r Extraer datos de Localización}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_2 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion2"]') %>% # Buscar el contenedor con los datos
  html_children() %>% 
  html_children() %>% # Bajar al segundo nivel (filas)
  html_text() %>% # Extraer el texto de los elementos
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Eliminar las dos primeras filas que contienen textos de los controles del mapa
datos_contenedor_2 <-
  datos_contenedor_2[c(-1, -2)]

# Eliminar la fila de título de "Otra localización:"
datos_contenedor_2 <-
  datos_contenedor_2[datos_contenedor_2 != "Otra localización:"]

# Agregar el nombre de la variable al dato de "Otra localización:"
datos_contenedor_2[length(datos_contenedor_2)] <-
  str_c("Otra localización: ", datos_contenedor_2[length(datos_contenedor_2)])

# Agregar un prefijo con la sección
datos_contenedor_2 <-
  str_c("S2_", datos_contenedor_2)

# Ver el resultado
datos_contenedor_2
```

```{r Extraer datos de Identificación}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_3_original <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion3"]') %>% # Buscar el siguiente contenedor
  html_children() %>% 
  html_children() %>% # Bajar al segundo nivel (filas)
  html_text() %>%  # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Separar los datos que vienen juntos en una misma fila
datos_contenedor_3_separados <-
  datos_contenedor_3_original[10] %>% 
  str_replace("Género:", "|Género:") %>% # Agregar un separador
  str_replace("Tipo Arquitectónico:", "|Tipo Arquitectónico:") %>% # Agregar un separador
  str_split("\\|") %>% # Separar usando el caracter definido
  unlist() # Convertir la lista resultante en un vector de tipo caracter

# Eliminar las filas de encabezados, agregar los datos separados y conservar los datos con nombre
datos_contenedor_3 <- c(
  datos_contenedor_3_original[c(1, 3:5, 7:8)],
  datos_contenedor_3_separados,
  datos_contenedor_3_original[12]
)

# Agregar un prefijo para diferenciar los datos originales de los actuales
datos_contenedor_3[2:4] <-
  str_c("original_", datos_contenedor_3[2:4])

datos_contenedor_3[7:9] <-
  str_c("actual_", datos_contenedor_3[7:9])

# Agregar un prefijo con la sección
datos_contenedor_3 <-
  str_c("S3_", datos_contenedor_3)

# Ver el resultado
datos_contenedor_3
```

```{r Extraer datos de Aspectos Legales}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_4_original <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion4"]') %>% # Buscar el siguiente contenedor
  html_children() %>%
  html_children() %>%
  html_children() %>% # Bajar al tercer nivel (filas)
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Separar los datos que vienen juntos en una misma fila
datos_contenedor_4_separados <-
  datos_contenedor_4_original[5] %>% 
  str_replace("Ubicado en la Zona de Monumentos Históricos:", "|Ubicado en la Zona de Monumentos Históricos:") %>% 
  str_replace("Sitio Inscrito en la lista de patrimonio Mundial UNESCO:", "|Sitio Inscrito en la lista de patrimonio Mundial UNESCO:") %>% 
  str_split("\\|") %>% 
  unlist()

# Unir los datos extraídos correctamente y los que se separaron
datos_contenedor_4 <-
  c(
    datos_contenedor_4_original[1:4],
    datos_contenedor_4_separados
  )

# Agregar un prefijo con la sección
datos_contenedor_4 <-
  str_c("S4_", datos_contenedor_4)

# Ver el resultado
datos_contenedor_4
```

```{r Extraer datos de Información Histórica}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_5 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion6"]') %>%  # Buscar el siguiente contenedor
  html_children() %>% 
  html_children() %>% 
  html_children() %>% # Bajar al tercer nivel (filas)
  html_text() %>%  # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Agregar los nombres de las variables a los datos:
datos_contenedor_5[5] <- 
  str_c(datos_contenedor_5[4], " ", datos_contenedor_5[5])

datos_contenedor_5[8] <- 
  str_c(datos_contenedor_5[7], " ", datos_contenedor_5[8])

datos_contenedor_5[11] <- 
  str_c(datos_contenedor_5[10], " ", datos_contenedor_5[11])

# Quitar las filas de encabezados 
datos_contenedor_5 <-
  datos_contenedor_5[c(-1, -4, -6, -7, -10)]

# Agregar un prefijo con la sección
datos_contenedor_5 <-
  str_c("S5_", datos_contenedor_5)
  
# Ver el resultado
datos_contenedor_5
```

```{r Extraer datos de Fuentes Consultadas}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_6 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion7"]') %>% # Buscar el siguiente contenedor
  html_children() %>% # Bajar al primer nivel (filas)
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Quitar filas vacías
datos_contenedor_6 <-
  datos_contenedor_6[datos_contenedor_6 != ""]

# Agregar un prefijo con la sección
datos_contenedor_6 <-
  str_c("S6_", datos_contenedor_6)

# Ver el resultado
datos_contenedor_6
```

```{r Extraer datos de monografía}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_7 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion8"]') %>% # Buscar el siguiente contenedor
  html_children() %>% # Bajar al primer nivel (filas)
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Quitar filas vacías
datos_contenedor_7 <-
  datos_contenedor_7[datos_contenedor_7 != ""]

# Agregar un prefijo con la sección y el nombre de la variable
datos_contenedor_7 <-
  str_c("S7_Monografia: ", datos_contenedor_7)

# Ver el resultado
datos_contenedor_7
```

```{r Extraer datos de Descripción Arquitectónica}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_8 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion11"]') %>% # Buscar el siguiente contenedor
  html_children() %>% # Bajar al primer nivel (filas)
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Quitar filas vacías
datos_contenedor_8 <-
  datos_contenedor_8[datos_contenedor_8 != ""]

datos_contenedor_8 <-
  str_c("S8_", datos_contenedor_8)

# Ver el resultado
datos_contenedor_8
```

```{r Extraer Características}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_9 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion12"]') %>% # Buscar el siguiente contenedor
  html_children() %>% 
  html_children() %>% 
  html_children() %>% # Bajar al tercer nivel (filas)
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Definir un prefijo inicial
prefijo <- ""

# Agregar el prefijo de encabezado correspondiente a cada elemento extraido
for(i in 1:length(datos_contenedor_9)) {
  
  if(!str_detect(datos_contenedor_9[i], "^*:")) {
    prefijo <- datos_contenedor_9[i]
  }
  
  datos_contenedor_9[i] <- str_c(str_trunc(prefijo, 6, ellipsis = ""), # Usar las primeras letras del encabezado
                                 "_", 
                                 datos_contenedor_9[i])
  
}

# Agregar un prefijo con la sección
datos_contenedor_9 <- str_c("S9_", datos_contenedor_9) 

# Quitar las cabeceras (elementos sin ":")
datos_contenedor_9 <- 
  datos_contenedor_9[str_detect(datos_contenedor_9, "^*:")]

# Ver el resultado
datos_contenedor_9
```

```{r Extraer Fecha de Elaboración o Actualización}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_10 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion17"]') %>% # Buscar el siguiente contenedor
  html_children() %>% 
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Agregar el prefijo y conservar la fecha más reciente:
datos_contenedor_10 <- 
  str_c("S10_", datos_contenedor_10) %>% 
  head()

# Ver el resultado
datos_contenedor_10
```

```{r Extrae datos PAHJE}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_11 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion22"]') %>% # Buscar el siguiente contenedor
  html_element(xpath = '//*[@id="divSeccion22"]/div[1]/div[2]/p') %>% 
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto
  
# Agregar el nombre del campo al valor:
datos_contenedor_11 <- c(str_c("S11_Planoteca del AHJE: ", datos_contenedor_11),
                         str_c("S11_URL Planoteca del AHJE: https://catalogonacionalmhi.inah.gob.mx/consulta_publica/generarPdfPlanoteca/", 9000))

# Ver el resultado
datos_contenedor_11
```

```{r Extraer datos AHJE}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_12 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion23"]') %>% # Buscar el siguiente contenedor
  html_element(xpath = '//*[@id="divSeccion23"]/div[1]/div[2]') %>% 
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Agregar el nombre del campo al valor:
datos_contenedor_12 <- c(str_c("S12_AHJE: ", datos_contenedor_12),
                         str_c("S12_URL AHJE: https://catalogonacionalmhi.inah.gob.mx/consulta_publica/generarPdfArchivoHistorico/", 9000))

# Ver el resultado
datos_contenedor_12
```

```{r Extraer datos FCRV}
# Buscar el siguiente contenedor y extraer los datos
datos_contenedor_13 <-
  html_ficha %>% 
  html_element(xpath = '//*[@id="divSeccion24"]') %>% # Buscar el siguiente contenedor
  html_element(xpath = '//*[@id="divSeccion24"]/div[1]/div[2]') %>% 
  html_text() %>% # Extraer el texto de cada elemento que se encontró
  str_remove_all("\n") %>% # Eliminar todos los saltos de línea
  str_squish() # Eliminar los espacios en blanco antes y después del texto

# Agregar el nombre del campo al valor:
datos_contenedor_13 <- c(str_c("S13_FCRV: ", datos_contenedor_13),
                         str_c("S13_URL FCRV: https://catalogonacionalmhi.inah.gob.mx/consulta_publica/generarPdfFototeca/", 9000))

# Ver el resultado
datos_contenedor_13
```

Unir los datos extraídos:

```{r Unir los valores extraidos}
# Unir los valores extraidos
datos_contenedor <- c(str_c("ID: ", 9000), # Agregar el ID de la página
                      datos_contenedor_1,
                      datos_contenedor_mapa,
                      datos_contenedor_2,
                      datos_contenedor_3,
                      datos_contenedor_4,
                      datos_contenedor_5,
                      datos_contenedor_6,
                      datos_contenedor_7,
                      datos_contenedor_8,
                      datos_contenedor_9,
                      datos_contenedor_10,
                      datos_contenedor_11,
                      datos_contenedor_12,
                      datos_contenedor_13)

datos_contenedor
```

Convertir el listado de datos extraídos en un registro de tabla:

Para que `pivot_wider` funcione correctamente en este caso, es necesario que no haya nombres de campos repetidos.

```{r Contruir el registro}
# Construir un tibble con un registro con los datos extraídos
registro_extraido <-
  tibble(lista = datos_contenedor) %>% # Nuevo tibble con una columna con la lista
  separate(lista, into = c("variable", "valor"), sep = ":", extra = "merge") %>% # Separar en los dos puntos
  mutate(variable = make_clean_names(variable)) %>%  
  pivot_wider(names_from = variable, values_from = valor) %>% # Voltear de filas a columnas
  glimpse() # Ver la estructura de datos
```

NOTA: NO HICE UNA FUNCIÓN POR QUE CADA DIV ESTÁ CONSTRUIDO DIFERENTE

## Automatización y extracción masiva

Hasta este punto, ya desarrollaste la secuencia de operaciones que se requieren para descargar los datos de una página en particular. Ahora debes repetir este proceso para cambiando el ID de la dirección de la página que genera la ficha para obtener los datos de todas las fichas posibles:

```         
https://catalogonacionalmhi.inah.gob.mx/consulta_publica/detalle/[ID de la página]
```

Donde debes iterar el valor de \[`ID de la página]` con números enteros.

Hasta este momento, es conveniente cerrar el servidor de Selemium y borrar el entorno para comenzar con la automatización de la página para la extración masiva de los datos.

Cierra las ventanas abiertas del explorador y apaga el servidor de Selenium:

```{r Cerrar explorador y servidor de Selenium}
# Cerrar todas las ventanas abiertas
controlador$closeall()

# Apagar el servidor de Selenium
servidor_selenium$server$stop()

# Borra todas las variables y objetos del entorno
rm(list = ls())
```

### Función para la extracción de datos

A partir de la secuencia de operaciones que creaste anteriormente, junta las instrucciones anteriores y construye una función que permita hacer el *scraping*, definiendo como parámetros el ID de la URL de la página de consulta y el controlador de Selenium que usarás para controlar el cambio de páginas.

```{r Función para extracción de datos}
# Definir la función para extraer los datos de una ficha
extraer_datos <- function(id_pagina, controlador, espera_carga = 3, espera_expandir = 3) {
  
  # Construir la URL usando el ID de la página que se pasa como parámetro (id_pagina):
  pagina_ficha <- str_c("https://catalogonacionalmhi.inah.gob.mx/consulta_publica/detalle/", id_pagina)
  
  # Ordenar al explorador que abra la página de la ficha con el ID deseado
  controlador$navigate(pagina_ficha)
  
  # Esperar a que cargue la página
  Sys.sleep(espera_carga)
  
  # Crear una instancia del botón Expandir todos
  boton_expandir_todos <- controlador$findElement(using = "xpath",
                                                  value = '//*[@id="btnExpandir"]')
  
  # Presionar el botón para expandir los contenedores
  boton_expandir_todos$clickElement()
  
  # Esperar a que se expandan las secciones
  Sys.sleep(espera_expandir)
  
  # Guarda el contenido de la página en una variable
  codigo_fuente <- controlador$getPageSource()
  
  # Extraer con rvest el código fuente de la lista obtenida con Selenium:
  html_ficha <- 
    read_html(codigo_fuente[[1]])
  
  
  # Buscar los elementos donde están los datos, extraer y limpiar el texto
  datos_contenedor_encabezado <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="encabezado"]') %>% 
    html_children() %>% 
    html_children() %>% 
    html_children() %>% 
    html_children() %>% # Expandir hasta los elementos de cuarto nivel (filas)
    html_text() %>% 
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Agregar nombres de variables faltantes
  datos_contenedor_encabezado[1] <- 
    str_c("Tipo: ", datos_contenedor_encabezado[1])
  
  datos_contenedor_encabezado[5] <- 
    str_c("Validación: ", datos_contenedor_encabezado[5])
  
  # Cosnervar las 5 primeras filas
  datos_contenedor_encabezado <-
    datos_contenedor_encabezado[1:5] 
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_1 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion1"]') %>% # Buscar el elemento del título
    html_children() %>% 
    html_children() %>% 
    html_children() %>% # Expandir hasta los elementos de tercer nivel (filas)
    html_text() %>% # Extraer el texto de los elementos
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Agregar un prefijo con la sección
  datos_contenedor_1 <- str_c("S1_", datos_contenedor_1)
  
  
  
  # Buscar la URL origen del mapa de Google
  datos_contenedor_mapa <-
    html_ficha %>%
    html_element(xpath = '//*[@id="divSeccion2"]') %>% # Buscar la sección donde está el mapa
    html_element("a") %>% # Buscar el primer link con la URL del mapa
    html_attr("href") %>%  # Extraer la URL del mapa
    replace_na("") # Si no hay mapa, reemplazar el valor vacío NA con un espacio
  
  # Agregar el nombre del campo al valor:
  datos_contenedor_mapa <-
    str_c("S2_Google Maps: ",
          datos_contenedor_mapa)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_2 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion2"]') %>% # Buscar el contenedor con los datos
    html_children() %>% 
    html_children() %>% # Bajar al segundo nivel (filas)
    html_text() %>% # Extraer el texto de los elementos
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Eliminar las dos primeras filas que contienen textos de los controles del mapa
  datos_contenedor_2 <-
    datos_contenedor_2[c(-1, -2)]
  
  # Eliminar la fila de título de "Otra localización:"
  datos_contenedor_2 <-
    datos_contenedor_2[datos_contenedor_2 != "Otra localización:"]
  
  # Agregar el nombre de la variable al dato de "Otra localización:"
  datos_contenedor_2[length(datos_contenedor_2)] <-
    str_c("Otra localización: ", datos_contenedor_2[length(datos_contenedor_2)])
  
  # Agregar un prefijo con la sección
  datos_contenedor_2 <-
    str_c("S2_", datos_contenedor_2)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_3_original <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion3"]') %>% # Buscar el siguiente contenedor
    html_children() %>% 
    html_children() %>% # Bajar al segundo nivel (filas)
    html_text() %>%  # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Separar los datos que vienen juntos en una misma fila
  datos_contenedor_3_separados <-
    datos_contenedor_3_original[10] %>% 
    str_replace("Género:", "|Género:") %>% # Agregar un separador
    str_replace("Tipo Arquitectónico:", "|Tipo Arquitectónico:") %>% # Agregar un separador
    str_split("\\|") %>% # Separar usando el caracter definido
    unlist() # Convertir la lista resultante en un vector de tipo caracter
  
  # Eliminar las filas de encabezados, agregar los datos separados y conservar los datos con nombre
  datos_contenedor_3 <- c(
    datos_contenedor_3_original[c(1, 3:5, 7:8)],
    datos_contenedor_3_separados,
    datos_contenedor_3_original[12]
  )
  
  # Agregar un prefijo para diferenciar los datos originales de los actuales
  datos_contenedor_3[2:4] <-
    str_c("original_", datos_contenedor_3[2:4])
  
  datos_contenedor_3[7:9] <-
    str_c("actual_", datos_contenedor_3[7:9])
  
  # Agregar un prefijo con la sección
  datos_contenedor_3 <-
    str_c("S3_", datos_contenedor_3)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_4_original <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion4"]') %>% # Buscar el siguiente contenedor
    html_children() %>%
    html_children() %>%
    html_children() %>% # Bajar al tercer nivel (filas)
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Separar los datos que vienen juntos en una misma fila
  datos_contenedor_4_separados <-
    datos_contenedor_4_original[5] %>% 
    str_replace("Ubicado en la Zona de Monumentos Históricos:", "|Ubicado en la Zona de Monumentos Históricos:") %>% 
    str_replace("Sitio Inscrito en la lista de patrimonio Mundial UNESCO:", "|Sitio Inscrito en la lista de patrimonio Mundial UNESCO:") %>% 
    str_split("\\|") %>% 
    unlist()
  
  # Unir los datos extraídos correctamente y los que se separaron
  datos_contenedor_4 <-
    c(
      datos_contenedor_4_original[1:4],
      datos_contenedor_4_separados
    )
  
  # Agregar un prefijo con la sección
  datos_contenedor_4 <-
    str_c("S4_", datos_contenedor_4)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_5 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion6"]') %>%  # Buscar el siguiente contenedor
    html_children() %>% 
    html_children() %>% 
    html_children() %>% # Bajar al tercer nivel (filas)
    html_text() %>%  # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Agregar los nombres de las variables a los datos:
  datos_contenedor_5[5] <- 
    str_c(datos_contenedor_5[4], " ", datos_contenedor_5[5])
  
  datos_contenedor_5[8] <- 
    str_c(datos_contenedor_5[7], " ", datos_contenedor_5[8])
  
  datos_contenedor_5[11] <- 
    str_c(datos_contenedor_5[10], " ", datos_contenedor_5[11])
  
  # Quitar las filas de encabezados 
  datos_contenedor_5 <-
    datos_contenedor_5[c(-1, -4, -6, -7, -10)]
  
  # Extraer el texto de cada elemento que se encontró
  datos_contenedor_5 <-
    str_c("S5_", datos_contenedor_5)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_6 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion7"]') %>% # Buscar el siguiente contenedor
    html_children() %>% # Bajar al primer nivel (filas)
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Quitar filas vacías
  datos_contenedor_6 <-
    datos_contenedor_6[datos_contenedor_6 != ""]
  
  # Agregar un prefijo con la sección
  datos_contenedor_6 <-
    str_c("S6_", datos_contenedor_6)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_7 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion8"]') %>% # Buscar el siguiente contenedor
    html_children() %>% # Bajar al primer nivel (filas)
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Quitar filas vacías
  datos_contenedor_7 <-
    datos_contenedor_7[datos_contenedor_7 != ""]
  
  # Agregar un prefijo con la sección y el nombre de la variable
  datos_contenedor_7 <-
    str_c("S7_Monografia: ", datos_contenedor_7)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_8 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion11"]') %>% # Buscar el siguiente contenedor
    html_children() %>% # Bajar al primer nivel (filas)
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Quitar filas vacías
  datos_contenedor_8 <-
    datos_contenedor_8[datos_contenedor_8 != ""]
  
  datos_contenedor_8 <-
    str_c("S8_", datos_contenedor_8)
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_9 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion12"]') %>% # Buscar el siguiente contenedor
    html_children() %>% 
    html_children() %>% 
    html_children() %>% # Bajar al tercer nivel (filas)
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Definir un prefijo inicial
  prefijo <- ""
  
  # Agregar el prefijo de encabezado correspondiente a cada elemento extraido
  for(i in 1:length(datos_contenedor_9)) {
    
    if(!str_detect(datos_contenedor_9[i], "^*:")) {
      prefijo <- datos_contenedor_9[i]
    }
    
    datos_contenedor_9[i] <- str_c(str_trunc(prefijo, 6, ellipsis = ""), # Usar las primeras letras del encabezado
                                   "_", 
                                   datos_contenedor_9[i])
    
  }
  
  # Agregar un prefijo con la sección
  datos_contenedor_9 <- str_c("S9_", datos_contenedor_9) 
  
  # Quitar las cabeceras (elementos sin ":")
  datos_contenedor_9 <- 
    datos_contenedor_9[str_detect(datos_contenedor_9, "^*:")]
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_10 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion17"]') %>% # Buscar el siguiente contenedor
    html_children() %>% 
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Agregar el prefijo y conservar la fecha más reciente:
  datos_contenedor_10 <- 
    str_c("S10_", datos_contenedor_10) %>% 
    head()
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_11 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion22"]') %>% # Buscar el siguiente contenedor
    html_element(xpath = '//*[@id="divSeccion22"]/div[1]/div[2]/p') %>% 
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Agregar el nombre del campo al valor:
  datos_contenedor_11 <- c(str_c("S11_Planoteca del AHJE: ", datos_contenedor_11),
                           str_c("S11_URL Planoteca del AHJE: https://catalogonacionalmhi.inah.gob.mx/consulta_publica/generarPdfPlanoteca/", id_pagina))
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_12 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion23"]') %>% # Buscar el siguiente contenedor
    html_element(xpath = '//*[@id="divSeccion23"]/div[1]/div[2]') %>% 
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Agregar el nombre del campo al valor:
  datos_contenedor_12 <- c(str_c("S12_AHJE: ", datos_contenedor_12),
                           str_c("S12_URL AHJE: https://catalogonacionalmhi.inah.gob.mx/consulta_publica/generarPdfArchivoHistorico/", id_pagina))
  
  
  # Buscar el siguiente contenedor y extraer los datos
  datos_contenedor_13 <-
    html_ficha %>% 
    html_element(xpath = '//*[@id="divSeccion24"]') %>% # Buscar el siguiente contenedor
    html_element(xpath = '//*[@id="divSeccion24"]/div[1]/div[2]') %>% 
    html_text() %>% # Extraer el texto de cada elemento que se encontró
    str_remove_all("\n") %>% # Eliminar todos los saltos de línea
    str_squish() # Eliminar los espacios en blanco antes y después del texto
  
  # Agregar el nombre del campo al valor:
  datos_contenedor_13 <- c(str_c("S13_FCRV: ", datos_contenedor_13),
                           str_c("S13_URL FCRV: https://catalogonacionalmhi.inah.gob.mx/consulta_publica/generarPdfFototeca/", id_pagina))
  
  
  # Unir los valores extraidos
  datos_contenedor <- c(str_c("ID: ", id_pagina), # Agregar el ID de la página
                        datos_contenedor_encabezado,
                        datos_contenedor_1,
                        datos_contenedor_mapa,
                        datos_contenedor_2,
                        datos_contenedor_3,
                        datos_contenedor_4,
                        datos_contenedor_5,
                        datos_contenedor_6,
                        datos_contenedor_7,
                        datos_contenedor_8,
                        datos_contenedor_9,
                        datos_contenedor_10,
                        datos_contenedor_11,
                        datos_contenedor_12,
                        datos_contenedor_13)
  
  
  # Construir un tibble con un registro con los datos extraídos
  registro_extraido <-
    tibble(lista = datos_contenedor) %>% # Nuevo tibble con una columna con la lista
    separate(lista, into = c("variable", "valor"), sep = ":", extra = "merge") %>% # Separar en los dos puntos
    mutate(variable = make_clean_names(variable)) %>%  
    pivot_wider(names_from = variable, values_from = valor) # Voltear de filas a columnas
  
  
  # Salida en pantalla para ver el avance de la extracción de la ficha
  str_c("Extrayendo datos [", id_pagina, "] ...") %>% 
    print()
  
  # Finalmente, regresar como resultado de la función el tibble con el registro extraido
  return(registro_extraido)
  
} 
```

### Extracción masiva

```{r}
# Iniciar el servidor de Selenium
servidor_selenium <- rsDriver(browser = "firefox")

# Crear el controlador del explorador web
controlador <- servidor_selenium$client
```

```{r}
# Iterar el número de ID de la página para extraer los datos
id_inicial <- 1
id_final <- 100

datos_acumulados <- map_df(id_inicial:id_final,
                           extraer_datos,
                           controlador)

datos_acumulados %>% 
  glimpse()
```

Guardar el archivo con los datos extraídos:

```{r Guardar los datos en un archivo}
datos_acumulados %>% 
  write_excel_csv(str_c("Datos/inah_monumentos_historicos_",
                        str_pad(id_inicial, width = 5, pad = "0"),
                        "-",
                        str_pad(id_final, width = 5, pad = "0"),
                        ".csv"))
```

Cierra las ventanas abiertas del explorador y apaga el servidor de Selenium:

```{r Cerrar explorador y servidor de Selenium}
# Cerrar todas las ventanas abiertas
controlador$closeall()

# Apagar el servidor de Selenium
servidor_selenium$server$stop()

# Borra todas las variables y objetos del entorno
rm(list = ls())
```

### Geocodificación

NOTA: Por seguridad, no compartas tu llave de API, puedes copiar la instrucción y ejecutarla en la consola para no guardarla en este cuaderno.

```{r}
# Establece tu llave API de Here en cada nueva sesión de trabajo.
Sys.setenv("HERE_API_KEY" = "TU_API_KEY_AQUI")
```

```{r}
# Leer los datos extraídos:
datos_acumulados <-
  read_csv("Datos/inah_monumentos_historicos_00001-00100.csv")

# Concatenar textos para obtener la dirección en una sola variable y geocodificar:
datos_geocodificados <-
  datos_acumulados %>% 
  mutate_at(c("s2_nombre_de_la_vialidad",
              "s2_numero_exterior",
              "s2_tipo_y_nombre_del_asentamiento_humano",
              "s2_localidad_colonia",
              "s2_municipio_alcaldia",
              "s2_entidad_federativa"),
            str_replace_na,
            "") %>% 
  mutate(direccion = str_c(s2_nombre_de_la_vialidad,
                           " ",
                           s2_numero_exterior,
                           ", ",
                           s2_localidad_colonia,
                           ", ",
                           s2_municipio_alcaldia,
                           ", ",
                           s2_entidad_federativa,
                           ", México")) %>% 
  select(id, direccion) %>%
  slice_sample(n = 10) %>% 
  geocode(address = "direccion")
```

```{r}
tmap_mode("view")

datos_geocodificados %>% 
  st_as_sf(coords = c("long", "lat"),
           crs = 4326,
           remove = FALSE,
           na.fail = FALSE) %>% 
  qtm()
```

---
title: "2. Introducción al Tidyverse y exportación/importación de datos"
author: "Ana J. Alegre (jalegre@centrogeo.edu.mx), Cristian Silva (csilva@centrogeo.edu.mx)"
---

## Introducción

El *data wrangling*, también conocido como *limpieza de datos* se refiere al proceso manual o automatizado mediante el cual los datos crudos son transformados en formatos más útiles para el análisis. Estos procesos incluyen la identificación de faltantes de infromación, la eliminación de datos irrelevantes, la combinación de múltiples fuentes de datos o la transformación de su estructura en una más apropiada (más conocida como *datos ordenados*).

Es posible usar el lenguaje *R* para leer, escribir y manipular datos que provienen de diferentes formatos, desde texto plano en *CSV* hasta formatos espaciales como *Shapefile*, *GeoPackage*, imágenes raster en *TIFF* entre otras. Una de las ventajas de usar *R* para el manejo de datos es la posibilidad de automatizar procesos previos al análisis de datos para ahorrar tiempo.

## Objetivo

El primer objetivo de esta sesión es realizar ejercicios con las principales funciones del paquete `tidyverse` para la manipulación de datos (*data wrangling*) y así filtrar, ordenar, agrupar y crear nuevas columnas. Para ello, usaremos el conjunto de datos de muestra llamado `iris` que se incluye en la instalación básica de *R*.

A continuación analizaremos datos reales que el gobierno de México publica para estudiar los homicidios reportados desde diciembre de 2018 hasta marzo de 2022, y compararemos aquellos que ocurren en la Ciudad de México (CDMX) con los que se registraron en los demás estados del país. Entonces, el segundo objetivo de esta sesión es importar y preparar los datos usando las funciones del *Tidyverse*.

Finalmente, convertiremos datos con referencias geográficas a tipos de datos espaciales y los visualizaremos en un mapa básico.

## Repaso de Tidyverse

Siempre es recomendable limpiar el entorno antes de comenzar a trabajar. Ejecuta el siguiente *chunk* para limpiar todos los objetos del entorno:

```{r Limpiar entorno}
rm(list = ls())
```

```         
Recuerda que para limpiar el entorno actual de R, también puedes utilizar el botón de la escoba en el panel *Environment*.
```

Para esta sesión nos aseguraremos de tener instalados y actualizados todos los paquetes necesarios (descomenta la siguiente instrucción para instalar o actualizar los paquetes necesarios en caso de no tenerlos):

```{r Instalar paquetes}
# install.packages(c("tidyverse")
```

```         
Recuerda que también puedes instalar o actualizar los paquetes necesarios para la sesión usando el panel "Packages" de RStudio.
```

Carga el conjunto de datos de muestra `iris` en el entorno de R usando la función `data` y visualízalo en la siguiente línea:

```{r Cargar datos de muestra}
data("***") # Cargar el conjunto de datos "iris" en el entorno de R
*** # Visualizar los datos
```

Usa la función `library` para cargar el paquete `tidyverse` que usaremos para manipular los datos:

```{r Cargar el paquete tidyverse}
***(tidyverse)
```

### Exploración de datos

Visualiza rápidamente la estructura y contenidos de `iris`, usando la función `glimpse`:

```{r Previsualizar datos}
glimpse(***)
```

La función `glimpse` funciona como un equivalente en *Tidyverse* de la función básica `str`.

El operador conocido como *pipa* (`%>%`) toma el resultado de la instrucción anterior y lo convierte en la entrada de la siguiente instrucción. Reescribe la instrucción del *chunk* anterior, usando una *pipa*:

```{r Previsualizar datos usando pipa}
*** %>% 
  ***()
```

Encuentra los valores únicos de la variable `Species` del *dataframe* `iris` usando la función `distinct` y la sintaxis de *pipa*:

```{r Valores distintos}
*** %>% 
  ***(Species) # Valores únicos de Species
```

### Seleccionar variables

Selecciona las variables `Sepal.Length` y `Species` del *dataframe* `iris` usando sus nombres con la función `select` y visualiza el resultado usando `glimpse`:

```{r Seleccionar variables}
*** %>% 
  select(***, ***) %>% # Selecciona las variables deseadas
  glimpse() # Muestra la nueva estructura de datos
```

Selecciona las variables `Sepal.Length`, `Sepal.Width` y `Species`del *dataframe* `iris`y multiplícalas para crear una nueva variable llamada `Sepal.Multiply` usando la función `mutate` y visualiza el resultado usando `glimpse`:

```{r Crear nuevas variables}
*** %>% 
  ***(***, ***, ***) %>% # Seleccionar las variables
  mutate(Sepal.Multiply = *** * ***) %>% # A partir de las variables seleccionadas, crea una nueva
  ***() # Muestra la estructura de datos
```

### Filtrar los datos

Repite las operaciones anteriores pero conservando sólo las filas donde el valor de `Species` es *setosa*, usando la función `filter`:

```{r Filtrar los datos}
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>% 
  filter(Species == "***") # Filtra las filas donde Species sea igual a "setosa"
```

Repite las operaciones anteriores, pero conservando sólo las filas donde los valores de `Species` son *setosa* y *versicolor* y el valores de `Sepal.Length` es mayor que 4.5, usando la función `filter`:

```{r Filtrar datos con varias condiciones}
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>%
  filter(Species %in% c("***", "***") & Sepal.Length > ***)  # Filtra las filas con varias condiciones
```

### Ordenar los datos

Repite las operaciones anteriores y ordena los datos por `Sepal.Length` en orden ascendente usando la función `arrange`:

```{r Ordenar datos}
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>% 
  ***(*** %in% c("***", "***") & *** > ***) %>% 
  arrange(***) # Ordena las filas
```

Repite las operaciones anteriores ordenando los datos ahora por `Sepal.Length` en orden descendente usando `desc` y luego por `Sepal.Multiply` orden ascendente, usando la función `arrange`:

```{r Ordenar datos con diferentes variables}
*** %>% 
  ***(***, ***, ***) %>% 
  ***(*** = *** * ***) %>% 
  ***(*** %in% c("***", "***") & *** > ***) %>% 
  arrange(desc(***), ***) # Ordena las filas por Sepal.Length descendiente y Sepal.Multiply ascendente
```

### Agrupar y sumarizar los datos

Cuenta el número de observaciones (filas) por cada valor único de la variable `Species` del *dataframe* `iris`, usando la función `count`:

```{r Obtener cuenta}
*** %>% 
  count(***)
```

Para crear grupos categóricos usando variables se usa la función `group_by`. Agrupa los datos del *dataframe* `iris` usando el campo categórico `Species`:

```{r Agrupar datos}
*** %>% 
  group_by(***) # Agrupar datos por valor
```

Este conjunto de datos no tiene cambios visibles, pero se crearon grupos para calcular en ellos estadísticos como estos:

-   Número de observaciones (n, cuenta)
-   Sumatoria
-   Media
-   Mínimo
-   Máximo
-   Mediana
-   Desviación estándar

Crea nuevas columnas con los estadísticos de la variable `Petal.Length` agrupados por cada valor único de la variable `Species`, usando la función `summarize` después de la función `group_by` y definiendo cada uno de los estadísticos con las funciones `n` (conteo), `sum` (sumatoria), `min` (mínimo), `max` (máximo), `mean` (promedio), `median` (mediana) y `sd` (desviación estándar):

```{r Sumarizar datos}
*** %>% 
  group_by(***) %>% 
  summarize(Petal.Cuenta = n(),
            Petal.Sumatoria = sum(Petal.Length),
            Petal.Minimo = min(Petal.Length),
            Petal.Maximo = max(Petal.Length),
            Petal.Media = mean(Petal.Length),
            Petal.Mediana = median(Petal.Length),
            Petal.DesvEst = sd(Petal.Length))
```

Después de sumarizar los datos se conservan *agrupados*, es por eso que regularmente es necesario eliminar la agrupación y mantener el conjunto de datos transformado antes de realizar cualquier otra operación, para esto se usa la función `ungroup`. Repite la agrupación y sumarización del *chunk* anterior y desagrupa usando la función `ungroup`:

```{r Sumarizar y desagrupar datos}
*** %>% 
  ***(***) %>% 
  ***(Petal.Cuenta = ***(),
      Petal.Sumatoria = ***(***),
      Petal.Minimo = ***(***),
      Petal.Maximo = ***(***),
      Petal.Media = ***(***),
      Petal.Mediana = ***(***),
      Petal.DesvEst = ***(***)) %>% 
  ungroup()
```

## Caso práctico: Homicidios a nivel nacional

### Importar los datos

En esta sesión, usaremos los datos abiertos de incidencia delictiva que publica el *Secretariado Ejecutivo del Sistema Nacional de seguridad Pública (SESNSP)* que están disponibles en el portal de datos abiertos del Gobierno de México en <https://www.datos.gob.mx/busca/dataset/incidencia-delictiva-del-fuero-comun>. Estos datos contienen la información de delitos cometidos a nivel estatal y serán usados en el taller más adelante para comparar los niveles de homicidios que ocurrieron en la CDMX y en los demás estados del país.

Carga el paquete `lubridate` para manejar más fácilmente los tipos de datos fecha-hora del conjunto de datos, y también carga el paquete `janitor` para realizar algunos procesos de limpieza a los datos:

```{r Cargar librerías para manipulación y limpieza de datos}
***(lubridate)
***(janitor)
```

Este es un conjunto de datos que originalmente viene en un formato de texto plano separado por comas (*CSV*). Observa y ejecuta el siguiente *chunk* para leer el archivo de datos usando la función de `read_csv` de `tidyverse` (no la instrucción `read.csv` de *R* base) y asigna los datos a una nueva variable que se llame `delitos`:

```{r Leer datos}
fuente_de_datos <- "Datos/IDEFC_NM.csv" # Desde el archivo descargado en la carpeta Datos
# fuente_de_datos <- "https://github.com/cris-silva/centrogeo-taller-siggypp/raw/main/Datos/IDEFC_NM_abr22.csv" # Directo desde el sitio del repositorio

delitos <- 
  read_csv(file = fuente_de_datos,
           locale = locale(encoding = "WINDOWS-1252")) %>%  
  clean_names() %>% 
  glimpse() 
```

En el *chunk* anterior, puedes observar lo siguiente:

-   En la instrucción `read_csv` se incluye un parámetro `locale = locale(encoding = "WINDOWS-1252")`. Esto se usa por que los datos originales se crearon en Windows, y aunque se puede omitir, no especificar esto puede provocar que aparezcan caracteres incorrectos en los datos al importarlos en otros sistemas operativos como macOS o Linux que usan el tipo de codificación *UTF-8*. \# La función `clean_names` del paquete `janitor` convierte los nombres de las columnas a minúsculas, reemplaza los espacios con '\_' y reemplaza caracteres especiales y con acentos para evitar problemas al escribir códigos.

### Preparar los datos

Los datos agrupan los totales de delitos en 12 columnas para cada mes, pero esta estructura no es útil para filtrar los datos por rangos de fecha. Para poder filtrar los datos por fecha, será necesario tener una columna `mes` de tipo de datos *fecha* en una forma de tabla *larga*. El siguiente bloque ejecutará en cadena las siguientes operaciones:

1.  Transformar la estructura a una forma *larga*, guardando los nombres de cada columna de mes en una nueva columna llamada `mes_nombre` y sus valores en una nueva columna llamada `total` usando la función `pivot_longer`.
2.  Obtener el número del mes a partir de `mes_nombre` usando la función `case_when` para guardar el valor numérico correspondiente en una nueva columna llamada `mes_numero`.
3.  Construir el mes en formato *fecha* usando las columnas `ano`, `mes_numero` y el número 1 para asumir el primer día del mes, para lo que se usa la función `make_date` para crear una nueva columna llamada `mes`.
4.  Finalmente quitar las columnas `mes_nombre`, `mes_numero`, `ano` que ya son innecesarias usando la función `select` y el signo `-` para excluirlas del *tibble* resultante.

Observa cómo se construyó ésta secuencia usando las *pipas* en el siguiente *chunk*, ejecútalo y observa el resultado:

```{r Limpiar y transformar datos nacionales}
delitos <-
  delitos %>% 
  pivot_longer(cols = 8:19,
               names_to = "mes_nombre",
               values_to = "total") %>% 
  mutate(mes_numero = case_when(mes_nombre == "enero" ~ 1,
                                mes_nombre == "febrero" ~ 2,
                                mes_nombre == "marzo" ~ 3,
                                mes_nombre == "abril" ~ 4,
                                mes_nombre == "mayo" ~ 5,
                                mes_nombre == "junio" ~ 6,
                                mes_nombre == "julio" ~ 7,
                                mes_nombre == "agosto" ~ 8,
                                mes_nombre == "septiembre" ~ 9,
                                mes_nombre == "octubre" ~ 10,
                                mes_nombre == "noviembre" ~ 11,
                                mes_nombre == "diciembre" ~ 12)) %>%
  mutate(mes = make_date(ano, mes_numero, 1)) %>% 
  select(-ano, -mes_nombre, -mes_numero) %>% 
  glimpse()
```

Para conocer la clasificación de los delitos a partir de los datos, crea una lista de los tipos de delitos a partir de los datos. Para ello construye con *pipas* la siguiente secuencia de operaciones y guarda el resultado en una nueva variable llamada `lista_delitos`:

1.  Toma como base los datos del *tibble* `delitos`.
2.  Usa la función `distinct` para obtener las categorías únicas de las columnas `bien_juridico_afectado`, `tipo_de_delito`, `subtipo_de_delito` y `modalidad`.
3.  Ordena los datos usando los campos `bien_juridico_afectado`, `tipo_de_delito`, `subtipo_de_delito` y `modalidad` en ése orden con la función `arrange`.

En la línea siguiente visualiza el contenido del *tibble* `lista_delitos` resultante.

```{r Crear lista de delitos}
lista_delitos <-
  *** %>% 
  distinct(***, ***, ***, ****) %>% # Mantiene los valores únicos de las columnas
  arrange(***, ***, ***, ***) # Ordena los valores de forma ascendente

# Muestra la lista de delitos:
***
```

Obtén los datos de homicidios que ocurrieron **desde diciembre 2018 hasta junio 2020**. Primero, es necesario definir las fechas de inicio y fin del periodo que necesitamos. Usa la función `make_date` del paquete `lubridate` para construir las variables `mes_inicial` y `mes_final` con tipo de datos de fecha:

```{r Definir el periodo requerido}
mes_inicial <- make_date(2018, 12, 1) # 2018-12-01
mes_final <- ***(***, ***, ***) # 2020-06-30
```

Después, usa las *pipas* para arreglar los datos y guardar en una nueva variable llamada `homicidios` el resultado de la siguiente secuencia de operaciones:

1.  Toma el *tibble* `delitos` como base.
2.  Filtra los datos usando las condiciones `tipo_de_delito == "Homicidio"` y `mes %>% between(mes_inicial, mes_final)` para mantener sólo los datos de homicidios y sus subcategorías en el periodo indicado usando la función `filter`.
3.  Visualiza la estructura del *tibble* resultante usando la función `glimpse`.

```{r Filtrar datos nacionales}
homicidios <-
  *** %>% # Datos de delitos
  ***(*** == "***" & *** %>% between(***, ***)) %>% # Filtros aplicados
  ***() # Visualizar la estructura del tibble resultante
```

Para conocer la evolución de los homicidios en cada estado y en el tiempo, agrupa y sumariza los totales de homicidios por entidad y mes. Asigna a una variable llamada `homicidios_por_estado` el resultado de las siguientes operaciones:

1.  Toma el *tibble* homicidios como base.
2.  Agrupa los datos por cada `clave_ent`, `entidad`, y `mes`.
3.  Obtén la suma del total de homicidios (usando el parámetro `na.rm = TRUE` para omitir los registros vacíos o `NA`) y guárdala en una nueva columna llamada `homicidios_totales`.
4.  Desagrupa los datos.
5.  Visualiza la estructura resultante.

```{r Agrupar y sumarizar datos nacionales}
homicidios_por_estado <-
  *** %>% # Datos de homicidios
  ***(***, ***, ***) %>% # Agrupar por clave_ent, entidad, y mes
  ***(homicidios_totales = sum(***, na.rm = TRUE)) %>% # Sumarizar el total de delitos quitando vacíos
  ***() %>% # Desagrupar
  ***() # Visualizar la estructura del tibble resultante
```

### Exportar los datos

Finalmente, guarda una copia de `homicidios_por_estado` usando *pipas* y las funciones `write_csv` o `write_excel_csv` para guardar los datos en formato *CSV* en el archivo `homicidios_por_estado.csv` en la carpeta `Datos` (se usarán más adelante en el taller):

```{r Guardar datos nacionales en CSV}
# Descomenta la versión que quieras usar de las siguientes instrucciones:

# La instrucción write_csv respeta la codificación de Windows, macOS o Linux: 
# homicidios_por_estado %>% 
#   write_csv("***")

# Usa esta función si los datos se van a abrir en Excel:
homicidios_por_estado %>% 
  write_excel_csv("***")
```

## Caso práctico: Homicidios en la CDMX

### Delitos en la CDMX por puntos

Los datos que usaremos para estudiar los homicidios en la CDMX se obtienen del portal de datos abiertos de la CDMX en (<https://datos.cdmx.gob.mx/dataset/carpetas-de-investigacion-fgj-de-la-ciudad-de-mexico>)[<https://datos.cdmx.gob.mx/dataset/carpetas-de-investigacion-fgj-de-la-ciudad-de-mexico>]. Los registros de los delitos de este conjunto de datos están desagregados a nivel de detalle y tienen las coordenadas del lugar donde ocurrieron, lo cual nos permite usar esta información para crear una capa geográfica de puntos que será útil para el análisis geoespacial que realizaremos más adelante en este taller.

Existen diferentes paquetes para cargar, construir, manipular y visualizar datos espaciales. Para este ejercicio, carga los paquetes `sf` y `tmap`:

```{r Cargar paquetes para manipulación y visualización de datos espaciales}
***(sf) # Para manipulación de datos espaciales
***(tmap) # Para crear mapas temáticos
```

El paquete `sf` nos permite leer datos con geometrías como coordenadas o codificadas como *well-known-text* (*WKT*) para convertirlas a *simple features* (datos espaciales) siguiendo las siguientes instrucciones. Importa los datos *CSV* que servirán como base en una nueva variable llamada `delitos_cdmx` realizando la siguiente secuencia de operaciones:

1.  Lee el archivo `.zip` de la carpeta `Datos` usando la función `read_csv` (el archivo *CSV* está comprimido en formato *ZIP* para ahorrar espacio).
2.  Limpia los nombres de las columnas usando la función `clean_names`.
3.  Visualiza la estructura resultante usando la función `glimpse`.

```{r Leer los datos para espacializar}
sf_fuente_de_datos <- "Datos/carpetas_ss_junio2020.csv.zip" # La función read_csv puede leer archivos CSV comprimidos con ZIP

delitos_cdmx <-
  ***(sf_fuente_de_datos) %>% # Leer los datos CSV
  ***() %>% # Limpiar los nombres de columnas
  ***() # Visualizar la estructura resultante
```

A diferencia de los datos de incidencia delictiva a nivel nacional que publica el SESNSP, la FGJCDMX utiliza una clasificación de delitos diferente en sus datos, por lo tanto será necesario identificar las categorías de homicidios a partir de estos datos.

Construye una lista de delitos y guárdala en una nueva variable llamada ´lista_delitos_cdmx\`, realizando la siguiente secuencia de operaciones:

1.  Toma como base los datos de `delitos_cdmx`.
2.  Obtén los valores únicos del campo `categoria_delito` usando la función `distinct`.
3.  Ordena los valores en orden ascendente a partir de la variable `categoria_delito` usando la función `arrange`.

Finalmente visualiza el contenido del *tibble* `lista_delitos_cdmx`.

```{r Crea una lista de delitos para CDMX}
lista_delitos_cdmx <- 
  *** %>% # Datos a partir de delitos_cdmx
  ***(***) %>% # Valores únicos de categoría_delito
  ***(***) # Ordenar por categoria_delito

*** # Visualizar el contenido de la lista resultante
```

Para poder comparar los datos nacionales y los de la CDMX, es necesario filtrar los datos de homicidios para el mismo periodo de tiempo.

Construye una nueva variable llamada `homicidios_cdmx` con la siguiente secuencia de operaciones:

1.  Toma como base los datos de `delitos_cdmx`.
2.  Crea una nueva columna llamada `fecha` extrayendo sólo la fecha del campo `fecha_hechos` (que es de tipo fecha-hora), usando la función `date`.
3.  Filtra las filas usando las condiciones `categoria_delito == "HOMICIDIO DOLOSO"` y `fecha %>% between(mes_inicial, mes_final)` usando la función `filter`.
4.  Visualiza la estructura resultante con la función `glimpse`.

```{r Filtrar datos para CDMX}
homicidios_cdmx <-
  *** %>% 
  ***(fecha = date(***)) %>% # Crea una columna de tipo fecha (sin hora) a partir de "fecha_hechos" para poder filtrar
  ***(*** == "***" & *** %>% ***(***, ***)) %>% 
  ***()
```

Este conjunto de datos usa un sistema de coordenadas (CRS) con proyección geográfica *WGS84*, para mayor información sobre las proyecciones geográficas y códigos EPSG con que se representan, puedes consultar <https://epsg.io>.

Modifica el valor de la variable `homicidios_cdmx` para convertirlo en una tabla espacial (*simple features*), siguiendo la siguiente secuencia de operaciones

1.  Toma como base el valor original de `homicidios_cdmx`.
2.  Convierte los datos en *sf (simple features)* usando la función `st_as_sf` con los parámetros `coords = c("longitud", "latitud")` para especificar los nombres de las variables que contienen las coordenadas, `na.fail = FALSE` para permitir que las filas sin coordenadas se conviertan en geometrías vacías y `remove = FALSE` para conservar las variables de las coordenadas.
3.  Establece el sistema de coordenadas en que vienen las coordenadas, en este caso *WGS84 (que le corresponde el código EPSG 4326)* usando la función `st_set_crs`.
4.  Visualiza la nueva estructura con la función `glimpse`.

```{r Convertir datos a espaciales}
homicidios_cdmx <-
  *** %>% 
  ***(coords = c("***", "***"), # Definir los nombres de las columnas con las coordenadas
      na.fail = ***, # Dejar las filas sin coordenadas como geometrías vacías
      remove = ***) %>% # Mantener las columnas de las coordenadas
  ***(***) %>% # Usar la proyección WGS84 mediante su código EPSG 4326
  ***()
```

```         
Observa en el resultado que `homicidios_cdmx` ahora tiene una nueva columna llamada `geometry` con el tipo de datos `POINT` que indica que los datos tienen una geometría de puntos.
```

Una vez que has convertido los datos a *sf*, es posible usar cualquier función de *data wrangling* de *Tidyverse* en ellos, como `filter`, `mutate`, `arrange`, etc.

Previsualiza rápidamente los datos espacializados de `homicidios_cdmx` usando la función `qtm` del paquete `tmap`:

```{r Previsualizar datos espacializados}
qtm(***) # Crea un "Quick Thematic Map"
```

Por defecto se muestra una versión del mapa para imprimir (modo *"plot"*), pero también es posible visualizar los datos en un mapa web interactivo (modo *"view"*) cambiando el modo de visualización. Visualiza los puntos de `homicidios_cdmx` en un mapa interactivo anteponiendo a la función `qtm` la función `tmap_mode("view")` para cambiar el modo de visualización del mapa:

```{r Previsualizar datos espacializados con mapa web}
tmap_mode("***") # Cambia el modo de visualización del mapa
***(***) # Construye un QTM con los datos de homicidios
```

Intenta explorar el mapa desplazandote con arrastrando el mapa y hciendo acercamientos y alejamientos con la rueda del mouse o con los botones + y -. También intenta dar clic en los puntos y cambia el mapa base en el botón de capas.

### Exportar datos espaciales

Es posible escribir un archivo con los datos espaciales en formato *ESRI Shapefile*, pero no se recomienda por que este formato no puede almacenar correctamente las columnas de tipo fecha-hora. En su lugar se recomienda usar un formato más moderno como *GeoPackage*.

Guarda los puntos de `homicidios_cdmx` en los archivos `homicidios_cdmx.shp` (formato *Shapefile*) y `homicidios_cdmx.gpkg` (formato *Geopackage*) dentro de la carpeta `Datos` usando la función `st_write` y agregando el parámetro `delete_dsn = TRUE` para sobreescribir los archivos si ya existen (usaremos estos archivos más adelante en el taller):

```{r Guardar datos espaciales en un archivo}
# Guardar en formato Shapefile:
*** %>% 
  ***("Datos/homicidios_cdmx.shp", *** = ***) # Guarda como Shapefile, no recomendado si los datos tienen tipos fecha-hora

# Guardar en formato Geopackage:
*** %>% 
  ***("Datos/homicidios_cdmx.gpkg", *** = ***) # Guarda como Geopackage, recomendado!
```

### Importar un archivo de datos espaciales

En la carpeta `Datos` está guardado el archivo `mexico_estados.gpkg` que contiene una capa geográfica publicada por el **Instituto Nacional de Estadística y Geografía (INEGI)** que contiene los polígonos de las 32 entidades federativas de México. Importa el contenido de este archivo como un *sf* y guárdalo en la variable `estados_mexico` usando la función `st_read` y visualiza la estructura resultante usando la función `glimpse`:

```{r Importar datos espaciales}
estados_mexico <-
  st_read(***) %>% 
  ***()
```

Observa que en éste caso, el tipo de geometría es de clase `MULTIPOLYGON`, lo que indica que es una capa de polígonos. Para comprobarlo, visualiza en un mapa los polígonos de los estados que contiene `estados_mexico` usando la función `qtm`:

```{r Visualizar en un mapa los estados}
***(***)
```

```         
Opcionalmente, puedes cambiar el modo de visualización del mapa para impresión como lo hiciste anteriormente, para comparar cómo se ven.
```

## Formatos espaciales disponibles para leer/escribir

El paquete `sf` usa las librerías del sistema llamadas *GDAL/OGR* para guardar datos espaciales en cualquier formato disponible en sus controladores. Para ver una lista de los formatos en que se puede leer y escribir con el paquete `sf` usa la función `st_drivers`:

```{r Listar formatos espaciales disponibles}
***()
```

## Referencias

-   Wickham, H., & Grolemund, G. (2017). *R for data science: Import, tidy, transform, visualize and model data.* <https://r4ds.had.co.nz>. O'Reilly.
-   Lovelace, R., Nowosad, J., & Muenchow, J. (2019), *Geocomputation with R.* <https://geocompr.robinlovelace.net>. CRC Press.
-   Tennekes, M., Nowosad, J. (2021). *Elegant and informative maps with tmap.* Recuperado el 8 de septembiembre, 2021, desde <https://r-tmap.github.io/tmap-book/>
-   Engel, C. (2019). *Using Spatial Data with R.* cengel.github.io. Recuperado el 8 de septembiembre, 2021, desde [https://cengel.github.io/R-spatial/](https://cengel.github.io/R-spatial).
